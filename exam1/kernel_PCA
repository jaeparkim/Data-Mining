Here is an example using linear kernel:

D =
array([[2, 1],
[1, 3],
[3, 2],
[1, 5]])

using linear kernel k(x,y) = x^T y, we get the following kernel matrix
K =
array([[ 5,  5,  8,  7],
[ 5, 10,  9, 16],
[ 8,  9, 13, 13],
[ 7, 16, 13, 26]])

If you center the points in feature space (which is the same as input space
for the linear kernel), you get:
Dc =
array([[ 0.25, -1.75],
[-0.75,  0.25],
[ 1.25, -0.75],
[-0.75,  2.25]])

The centered kernel matrix is
Kc =
array([[ 3.125, -0.625,  1.625, -4.125],
[-0.625,  0.625, -1.125,  1.125],
[ 1.625, -1.125,  2.125, -2.625],
[-4.125,  1.125, -2.625,  5.625]])

you can also center K directly by using Eq 5.16,

Kc = (np.eye(4)-1/4np.ones((4,4))) @ K @ (np.eye(4)-1/4np.ones((4,4)))
array([[ 3.125, -0.625,  1.625, -4.125],
[-0.625,  0.625, -1.125,  1.125],
[ 1.625, -1.125,  2.125, -2.625],
[-4.125,  1.125, -2.625,  5.625]])

np.linalg.eigh(Kc)
(array([-1.26436182e-15,  7.09250307e-16,  1.32704850e+00,  1.01729515e+01]), array(
[[-0.10924585,  0.73100044,  0.41048354, -0.53404772],
[-0.79534597, -0.28352735,  0.50935617,  0.16611241],
[-0.56664593,  0.05464858, -0.73287316, 0.37258939],
[-0.18547919,  0.61827513, -0.18696654,  .74052471]]))

Now c1 is given as (-0.534, 0.166, 0.373, 0.741)^T rounded to 3 decimals.

and alpha1 = 10.173, so variance is alpha1/4 = 10.173/4 =2.543

Now we have to scale c1 by 1/sqrt(alpha) to get new c1:
c1 = c1*1/np.sqrt(10.173)
array([-0.16743858,  0.05208079, -0.11681698,  0.23217477])

So the first kernel PC is now a combination of the points in Xc according to the weights in c1 above, we get:
np.sum(Xc * c1.reshape(-1,1), axis=0)
array([-0.40107254,  0.91604369])

Note that this eigenvector is the same as the dominant eigenvector of the cov matrix for Xc, since
S =
array([[ 0.6875, -0.8125],
[-0.8125,  2.1875]])

np.linalg.eigh(S)
(array([0.33176212, 2.54323788]),
array([[-0.91604588, -0.4010735 ],
[-0.4010735 ,  0.91604588]]))

You can see that the largest eigenvalue is 2.543, and dominant eigenvector is (-0.401, 0.916).

We did this for the linear kernel, but same logic applies to poly or gaussian or any other kernel.

